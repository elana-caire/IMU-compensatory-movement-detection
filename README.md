# IMU_Compensatory_Movements

Pipeline-based framework for detecting compensatory movements from IMU data using feature extraction, LOSO training, time-split training, and post-hoc explainability (SHAP & permutation importance).

## ğŸ§° Setup Instructions

1. Clone the repository

git clone [<repository_url>](https://github.com/elana-caire/IMU-compensatory-movement-detection.git)

cd IMU_Compensatory_Movements

2. Create the Conda environment

This project uses a predefined Conda environment.

```bash
conda env create -f environment.yml
conda activate AI_health
```

âš ï¸ Make sure the environment name is AI_health

3. Download the Dataset

Download the dataset from the Polybox folder.

Unzip it.

Rename the folder Course Data â†’ Data

Place the Data/ folder in the root directory of this project:

IMU_Compensatory_Movements/
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ IMU Data/
â”‚   â”œâ”€â”€ Features/
â”‚   â””â”€â”€ ...
ğŸ“ Project Structure (Simplified)


IMU_Compensatory_Movements/
â”‚
â”œâ”€â”€ main.py                  # Pipeline entry point
â”‚
â”œâ”€â”€ scripts/                 # Executable pipeline steps
â”‚   â”œâ”€â”€ data_preparation.py
â”‚   â”œâ”€â”€ LOSO_task_agnostic_train.py
â”‚   â”œâ”€â”€ LOSO_task_specific_train.py
â”‚   â”œâ”€â”€ plot_average.py
â”‚   â”œâ”€â”€ LOSO_feature_importance.py
â”‚   â”œâ”€â”€ GLOBAL_train.py
â”‚   â””â”€â”€ GLOBAL_feature_importance.py
â”‚
â”œâ”€â”€ config/                  # All configuration files
â”‚   â”œâ”€â”€ paths.py
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ training_common.py
â”‚   â”œâ”€â”€ loso.py
â”‚   â””â”€â”€ global_time_split.py
â”‚
â”œâ”€â”€ utils/                   # Feature extraction & helpers
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md


## ğŸš€ Running the Full Pipeline (Recommended)

All steps are executed in the correct order using the main pipeline controller.

```bash
python main.py
```

This will run:

Data preparation & feature extraction

--> LOSO 

training

Task-agnostic models

Task-specific models

Average performance plots

Feature importance & SHAP

--> Global 

pick in config/time_split if you run task agnostic or task specific

(time-split) training 

feature importance & SHAP


## ğŸ§° Pipeline Steps (What Happens Internally)

### ğŸ”¹ STEP 1 â€“ Data Preparation

Script: scripts/data_preparation.py

Config: config/data_prep.py, config/paths.py

This step:

Loads raw IMU data

Filters signals and aligns them to movement onset

Extracts window-based features

Saves feature CSV files to Data/Features/

Key parameters (edit in config/data_prep.py)

WINDOW_SIZE_MS = [750]  # e.g. [None, 250, 500, 750, 1000]

Raw and output paths are defined centrally in:

config/paths.py


### ğŸ”¹ STEP 2 â€“ LOSO Model Training

2a â€“ Task-Agnostic LOSO Training

Script: scripts/LOSO_task_agnostic_train.py

Config:

config/training_common.py

config/loso.py

Trains models across all tasks combined using Leave-One-Subject-Out CV.

2b â€“ Task-Specific LOSO Training

Script: scripts/LOSO_task_specific_train.py

Trains separate LOSO models per task.

2c â€“ Average Performance Plots

Script: scripts/plot_average.py

Generates summary plots averaged across tasks and subjects.

2d â€“ Feature Importance & SHAP (LOSO)

Script: scripts/LOSO_feature_importance.py

Retrains top-performing LOSO models and computes:

Permutation Importance

SHAP values

Key parameters live in:

config/loso.py

### ğŸ”¹ STEP 3 â€“ Global (Time-Split) Training

3a â€“ Global Training

Script: scripts/GLOBAL_train.py

Config: config/global_time_split.py

Uses temporal splits instead of LOSO.

3b â€“ Global Feature Importance & SHAP

Script: scripts/GLOBAL_feature_importance.py

Computes explainability metrics for global models.

### âš™ï¸ Configuration Philosophy (Important)

âŒ No parameters are edited inside scripts

âœ… All parameters live in config/

âœ… Paths are centralized in config/paths.py

âœ… Scripts only import what they need

This ensures:

Reproducibility

Clean experiments

Easy review and modification

## ğŸ“Š Feature File Description

Example output file:

Data/Features/features_win_750.csv

Each row corresponds to one window from one:

subject

task

condition

Feature types

Time-domain

*_MAX, *_MIN, *_AMP, *_MEAN, *_RMS, *_STD, *_JERK, *_COR

Frequency-domain

*_DOMFREQ, *_DOMPOW, *_TOTPOW, *_SPEC_CENT, *_SPEC_SPREAD

Metadata

subject

task

condition

ğŸ§ª Example Usage (Loading Features)

import pandas as pd

feats = pd.read_csv("Data/Features/features_win_750.csv")

### Select subject

subj_feat = feats[feats["subject"] == "P02"]

### Select task
subj_task = subj_feat[subj_feat["task"] == "cup-placing"]


### âš ï¸ Important Notes

Do not run scripts directly

âŒ python scripts/data_preparation.py

Always use:

âœ… python main.py

This ensures correct imports and reproducible execution.